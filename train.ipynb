{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.autograd import grad as torch_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model, init_type='xavier', gain=0.02):\n",
    "   '''\n",
    "   initialize network's weights\n",
    "   init_type: normal | xavier | kaiming | orthogonal\n",
    "   '''\n",
    "\n",
    "   def init_func(m):\n",
    "       classname = m.__class__.__name__\n",
    "       if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "           if init_type == 'normal':\n",
    "               nn.init.normal_(m.weight.data, 0.0, gain)\n",
    "           elif init_type == 'xavier':\n",
    "#                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "           elif init_type == 'kaiming':\n",
    "               nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "           elif init_type == 'orthogonal':\n",
    "               nn.init.orthogonal_(m.weight.data, gain=gain)\n",
    "\n",
    "           if hasattr(m, 'bias') and m.bias is not None:\n",
    "               nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "       elif classname.find('BatchNorm2d') != -1:\n",
    "           nn.init.normal_(m.weight.data, 1.0, gain)\n",
    "           nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "   model.apply(init_func)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self, epsilon=1e-8):\n",
    "        \"\"\"\n",
    "            @notice: avoid in-place ops.\n",
    "            https://discuss.pytorch.org/t/encounter-the-runtimeerror-one-of-the-variables-needed-for-gradient-computation-has-been-modified-by-an-inplace-operation/836/3\n",
    "        \"\"\"\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        tmp  = torch.mul(x, x) # or x ** 2\n",
    "        tmp1 = torch.rsqrt(torch.mean(tmp, dim=1, keepdim=True) + self.epsilon)\n",
    "\n",
    "        return x * tmp1\n",
    "    \n",
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder, self).__init__()\n",
    "        self.conv_dim = 64\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 3, 2, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 16, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(16, 256, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(128, 64, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 3, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        out = self.decoder(feat) \n",
    "        return feat, out\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "class upblock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(upblock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            PixelNorm(),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            PixelNorm(),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv1(x)\n",
    "\n",
    "class generator(nn.Module):\n",
    "    def __init__(self, num_z, imsize=64):\n",
    "        super(generator, self).__init__()\n",
    "        self.conv_dim = 64\n",
    "        \n",
    "        if imsize == 64:\n",
    "            self.in_dim = self.conv_dim*4\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.Linear(num_z, self.conv_dim*4 * 4 * 4),\n",
    "            )\n",
    "            self.decoder = nn.Sequential(\n",
    "                PixelNorm(),\n",
    "                nn.ReLU(True),\n",
    "                upblock(self.conv_dim*4, self.conv_dim*2), # [8, 8]\n",
    "                upblock(self.conv_dim*2, self.conv_dim), # [16, 16]\n",
    "                nn.Conv2d(self.conv_dim, 16, 3, 1, 1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            self.in_dim = self.conv_dim*8\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.Linear(num_z, self.conv_dim*8 * 4 * 4),\n",
    "            )\n",
    "            self.decoder = nn.Sequential(\n",
    "                PixelNorm(),\n",
    "                nn.ReLU(True),\n",
    "                upblock(self.conv_dim*8, self.conv_dim*4), # [8, 8]\n",
    "                upblock(self.conv_dim*4, self.conv_dim*2), # [16, 16]\n",
    "                upblock(self.conv_dim*2, self.conv_dim), # [16, 16]\n",
    "                nn.Conv2d(self.conv_dim, 16, 3, 1, 1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x).view(x.size(0),self.in_dim,4,4)\n",
    "        x = self.decoder(x) \n",
    "        return x\n",
    "\n",
    "class code_discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, imsize=64):\n",
    "        super(code_discriminator, self).__init__()\n",
    "        conv_dim = 64\n",
    "        if imsize == 64:\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(16, conv_dim, 3, 1, 1), #[16,16]\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim, conv_dim*2, 3, 2, 1), #[8,8]\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim * 2, conv_dim*2, 3, 1, 1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim*2, conv_dim*4, 3, 2, 1), #[4,4]\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim*4, conv_dim*4, 3, 1, 1),\n",
    "                nn.ReLU(True),\n",
    "                Flatten(), \n",
    "                nn.Linear(conv_dim*4*4*4, 1),\n",
    "            )\n",
    "        else:\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(16, conv_dim, 3, 1, 1), #[16,16]\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim, conv_dim*2, 3, 2, 1), #[8,8]\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim * 2, conv_dim*2, 3, 1, 1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim*2, conv_dim*4, 3, 2, 1), #[4,4]\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim*4, conv_dim*4, 3, 1, 1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim*4, conv_dim*8, 3, 2, 1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(conv_dim*8, conv_dim*8, 3, 1, 1),\n",
    "                nn.ReLU(True),\n",
    "                Flatten(), \n",
    "                nn.Linear(conv_dim*8*4*4, 1),\n",
    "            )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        return out\n",
    "    \n",
    "class im_discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=64):\n",
    "        super(im_discriminator, self).__init__()\n",
    "        conv_dim = d        \n",
    "        self.encoder = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(3, conv_dim, 3, 2, 1)),\n",
    "            nn.ReLU(True),\n",
    "            spectral_norm(nn.Conv2d(conv_dim, conv_dim * 2, 3, 2, 1)),\n",
    "            nn.ReLU(True),\n",
    "            spectral_norm(nn.Conv2d(conv_dim * 2, conv_dim* 4, 3, 2, 1)),\n",
    "            nn.ReLU(True),\n",
    "            nn.utils.spectral_norm(nn.Conv2d(conv_dim * 4, conv_dim * 8, 3, 2, 1)),\n",
    "            nn.ReLU(True),\n",
    "            nn.utils.spectral_norm(nn.Conv2d(conv_dim * 8, conv_dim * 8, 3, 1, 1)),\n",
    "            nn.ReLU(True),\n",
    "            Flatten(), \n",
    "            spectral_norm(nn.Linear(conv_dim*8*4*4, 128)),\n",
    "            nn.ReLU(True),\n",
    "            spectral_norm(nn.Linear(128, 1)),\n",
    "        )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class im_dataset(Dataset):\n",
    "    def __init__(self, real_dir, imsize):\n",
    "        self.real_dir = real_dir\n",
    "        self.imgpaths = self.get_imgpaths()\n",
    "\n",
    "        self.preprocessing = transforms.Compose([\n",
    "                transforms.Resize(imsize),\n",
    "                transforms.CenterCrop(imsize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "\n",
    "    def get_imgpaths(self):\n",
    "        real_paths = sorted(glob.glob('%s/*.jpg'%self.real_dir, recursive=True))\n",
    "        return real_paths\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        truepath = self.imgpaths[idx]\n",
    "        true_im = self.preprocessing(Image.open(truepath))\n",
    "        if true_im.size(0) == 1:\n",
    "            return self.__getitem__(np.random.randint(0, self.__len__()))\n",
    "        \n",
    "        return true_im\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgpaths)\n",
    "\n",
    "def generate_recon(epoch, img):\n",
    "    encode_model.eval()\n",
    "    with torch.no_grad():\n",
    "        feat, out = encode_model(img)\n",
    "        pic = to_img(out.cpu().data)\n",
    "        save_image(pic, '%s/recon_%d.png'%(out_dir, epoch))\n",
    "        pic = to_img(img.cpu().data)\n",
    "        save_image(pic, '%s/original_%d.png'%(out_dir, epoch))\n",
    "    encode_model.train()\n",
    "        \n",
    "def generate_gan(epoch, fixed_z):\n",
    "    code_gen.eval()\n",
    "    encode_model.eval()\n",
    "    with torch.no_grad():\n",
    "        code = code_gen(fixed_z)\n",
    "        out = encode_model.decode(code)\n",
    "        pic = to_img(out.cpu().data)\n",
    "        save_image(pic, '%s/local_%d.png'%(out_dir, epoch))\n",
    "    code_gen.train()\n",
    "\n",
    "def adjust_learning_rate(optimizers, epoch, num_epochs):        \n",
    "    for optimizer in optimizers:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            current_lr = param_group['lr']\n",
    "            if epoch == 15:\n",
    "                new_lr = current_lr / 2\n",
    "            elif epoch == 30:\n",
    "                new_lr = current_lr / 5\n",
    "            else:\n",
    "                new_lr = current_lr\n",
    "            param_group['lr'] = new_lr\n",
    "            \n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "    Adversarial loss\n",
    "    https://arxiv.org/abs/1711.10337\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, type='nsgan', target_real_label=1.0, target_fake_label=0.0):\n",
    "        r\"\"\"\n",
    "        type = nsgan | lsgan | hinge\n",
    "        \"\"\"\n",
    "        super(AdversarialLoss, self).__init__()\n",
    "\n",
    "        self.type = type\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "\n",
    "        if type == 'nsgan':\n",
    "            self.criterion = nn.BCELoss()\n",
    "\n",
    "        elif type == 'lsgan':\n",
    "            self.criterion = nn.MSELoss()\n",
    "\n",
    "        elif type == 'hinge':\n",
    "            self.criterion = nn.ReLU()\n",
    "\n",
    "    def __call__(self, outputs, is_real, is_disc=None):\n",
    "        if self.type == 'hinge':\n",
    "            if is_disc:\n",
    "                if is_real:\n",
    "                    outputs = -outputs\n",
    "                return self.criterion(1 + outputs).mean()\n",
    "            else:\n",
    "                return (-outputs).mean()\n",
    "        elif self.type == 'wgan-gp':\n",
    "            if is_real:\n",
    "                outputs = -outputs\n",
    "            return outputs.mean()\n",
    "        else:\n",
    "            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n",
    "            if self.type == 'nsgan':\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            return loss\n",
    "\n",
    "        \n",
    "def gradient_penalty(real_data, generated_data, disc):\n",
    "    batch_size = real_data.size(0)\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1).cuda()\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    interpolated = (alpha * real_data + (1 - alpha) * generated_data).detach().requires_grad_()\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    prob_interpolated = disc(interpolated)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(prob_interpolated.size()).cuda(),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "    # so flatten to easily take norm per example in batch\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "\n",
    "    # Return gradient penalty\n",
    "    return 10 * ((gradients_norm - 1) ** 2).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './adv_training2'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    \n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "dataset = im_dataset('./data/img_align_celeba', 64)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_epochs = 50\n",
    "k = 128\n",
    "encode_model = encoder().cuda().train()\n",
    "code_gen = generator(k, 128).cuda().train()\n",
    "\n",
    "im_disc = im_discriminator().cuda().train()\n",
    "code_disc = code_discriminator(128).cuda().train()\n",
    "\n",
    "# encode_model.load_state_dict(torch.load('./adv_training2/encoder.pth'))\n",
    "\n",
    "adv_criterion = AdversarialLoss(type='wgan-gp').cuda()\n",
    "l1_criterion = nn.L1Loss()\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encode_model.parameters(), lr=1e-4)\n",
    "gen_optimizer = torch.optim.Adam(code_gen.parameters(), lr=1e-4, betas=(0, 0.9))\n",
    "\n",
    "im_disc_optimizer = torch.optim.Adam(im_disc.parameters(), lr=4e-4, betas=(0, 0.9))\n",
    "code_disc_optimizer = torch.optim.Adam(code_disc.parameters(), lr=4e-4, betas=(0, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train encoder - decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    for batch_idx, img in enumerate(dataloader):\n",
    "        img = img.cuda()\n",
    "        feat, out = encode_model(img)        \n",
    "        real_out = im_disc(img)\n",
    "        fake_out = im_disc(out.detach())\n",
    "\n",
    "        err_real = adv_criterion(real_out, True, True)\n",
    "        err_fake = adv_criterion(fake_out, False, True)\n",
    "        err_wgan = gradient_penalty(img, out.detach(), im_disc)\n",
    "        \n",
    "        gan_loss = err_real + err_fake + err_wgan\n",
    "                \n",
    "        im_disc_optimizer.zero_grad()\n",
    "        gan_loss.backward()\n",
    "        im_disc_optimizer.step()\n",
    "        \n",
    "        # generator\n",
    "        l1 = l1_criterion(out, img)\n",
    "        fake_out = im_disc(out)\n",
    "        adv_loss = adv_criterion(fake_out, True, False)\n",
    "        g_loss = l1 + 0.1*adv_loss\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(epoch, gan_loss.item(), l1.item(), adv_loss.item())\n",
    "            generate_recon(epoch, img)\n",
    "            \n",
    "    if epoch % 1 == 0:\n",
    "        torch.save(encode_model.state_dict(), '%s/encode_model.pth'%out_dir)\n",
    "        torch.save(im_disc.state_dict(), '%s/im_disc.pth'%out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 128 generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = im_dataset('./data/img_align_celeba', 128)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "fixed_z = torch.randn([batch_size, k]).cuda()\n",
    "\n",
    "for epoch in range(50):\n",
    "    for batch_idx, img in enumerate(dataloader):\n",
    "        img = img.cuda()\n",
    "        z = torch.randn([img.size(0), k]).cuda()\n",
    "        with torch.no_grad():\n",
    "            real_feat, _ = encode_model(img)  \n",
    "            \n",
    "        fake_feat = code_gen(z)\n",
    "        \n",
    "        real_out = code_disc(real_feat)\n",
    "        fake_out = code_disc(fake_feat.detach())\n",
    "\n",
    "        err_real = adv_criterion(real_out, True, True)\n",
    "        err_fake = adv_criterion(fake_out, False, True)\n",
    "        err_wgan = gradient_penalty(real_feat, fake_feat.detach(), code_disc)\n",
    "\n",
    "        gan_loss = err_real + err_fake + err_wgan\n",
    "                \n",
    "        code_disc_optimizer.zero_grad()\n",
    "        gan_loss.backward()\n",
    "        code_disc_optimizer.step()\n",
    "        \n",
    "        # generator\n",
    "        fake_out = code_disc(fake_feat)\n",
    "        adv_loss = adv_criterion(fake_out, True, False)\n",
    "        \n",
    "        gen_optimizer.zero_grad()\n",
    "        adv_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(epoch, gan_loss.item(), adv_loss.item())\n",
    "            generate_gan(epoch, fixed_z)\n",
    "    if epoch % 1 == 0:\n",
    "        torch.save(code_gen.state_dict(), '%s/code_gen.pth'%out_dir)\n",
    "        torch.save(code_disc.state_dict(), '%s/code_disc.pth'%out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
